import io
import pandas as pd
import streamlit as st
import re

st.set_page_config(page_title="ğŸ“¦ æ¬ å“ Ã— å‡ºè· çµ±åˆãƒ„ãƒ¼ãƒ«", layout="wide")
st.title("ğŸ“¦ æ¬ å“æ—¥æ•° Ã— å‡ºè·ãƒ‡ãƒ¼ã‚¿ Ã— å•†å“çŠ¶æ…‹ çµ±åˆãƒ„ãƒ¼ãƒ«")

file_uploaded = st.file_uploader(" çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè¤‡æ•°ã‚·ãƒ¼ãƒˆæ§‹æˆï¼‰", type=["xlsx"])

if file_uploaded:
    try:
        xls = pd.ExcelFile(file_uploaded)
        df_ketsu_raw = None
        df_ship_raw = None
        df_sales_raw = None
        df_status = pd.DataFrame()

        for sheet_name in xls.sheet_names:
            df_tmp = pd.read_excel(xls, sheet_name=sheet_name)
            columns = df_tmp.columns
            columns_str = columns.astype(str)

            if df_ship_raw is None and 'å•†å“ã‚³ãƒ¼ãƒ‰' in columns_str and any('æ—¥ä»˜' in str(c) or 'å‡ºè·' in str(c) for c in columns_str):
                df_ship_raw = df_tmp
                st.success(f"âœ”ï¸ å‡ºè·ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡ºï¼š{sheet_name}")

            elif df_ketsu_raw is None and 'å•†å“ã‚³ãƒ¼ãƒ‰' in columns_str and any(re.match(r'\d{1,2}æœˆ(0001|1001|2001)', str(col)) for col in columns_str):
                df_ketsu_raw = df_tmp
                st.success(f"âœ”ï¸ æ¬ å“ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡ºï¼š{sheet_name}")

            elif df_sales_raw is None and 'å•†å“ã‚³ãƒ¼ãƒ‰' in columns_str:
                count_date_cols = sum(bool(re.search(r'20\d{2}[/å¹´\-]\d{1,2}', str(col))) for col in columns_str)
                if count_date_cols >= 3:
                    df_sales_raw = df_tmp
                    st.success(f"âœ”ï¸ è²©å£²é‡ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œå‡ºï¼š{sheet_name}")

            columns_str = df_tmp.columns.astype(str)
        if 'å•†å“ã‚³ãƒ¼ãƒ‰' in columns_str:
            # è¯†åˆ«æ‰€æœ‰åˆ—åä¸­å¸¦æœ‰å…³é”®å­—çš„åˆ—
            status_cols = [
                col for col in columns_str
                if any(keyword in col for keyword in ['åŒºåˆ†', 'çŠ¶æ…‹', 'ç†ç”±', 'çŠ¶æ€'])
            ]
            # éå†è¿™äº›åˆ—ï¼Œé€æ¡æå–åˆ° df_status
            for sc in status_cols:
                # æŠ½å–â€œå•†å“ã‚³ãƒ¼ãƒ‰â€ + è¯¥çŠ¶æ€åˆ—
                tmp = df_tmp[['å•†å“ã‚³ãƒ¼ãƒ‰', sc]].dropna(subset=[sc])
                # é‡å‘½åï¼šæŠŠ sc ç»Ÿä¸€æˆ 'å•†å“çŠ¶æ…‹'
                tmp = tmp.rename(columns={sc: 'å•†å“çŠ¶æ…‹'})
                df_status = pd.concat([df_status, tmp], ignore_index=True)

    except Exception as e:
        st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

    if df_ship_raw is None or df_ketsu_raw is None:
        st.error("âŒ æ¬ å“ã¾ãŸã¯å‡ºè·ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
        st.stop()

    months = [f"{i}æœˆ" for i in range(1, 13)]
    warehouse_codes = ["0001", "1001", "2001"]
    ketsu_records = []
    for _, row in df_ketsu_raw.iterrows():
        code = row.get("å•†å“ã‚³ãƒ¼ãƒ‰")
        if pd.isna(code):
            continue
        for month in months:
            vals = []
            for w in warehouse_codes:
                col_name = f"{month}{w}"
                val = pd.to_numeric(row.get(col_name, 0), errors='coerce') or 0
                vals.append(val)
            total = sum(vals)
            ketsu_records.append({
                "å•†å“ã‚³ãƒ¼ãƒ‰": str(code).strip(),
                "å¹´æœˆ": month,
                "0001å€‰åº«æ¬ å“æ—¥æ•°": vals[0],
                "1001å€‰åº«æ¬ å“æ—¥æ•°": vals[1],
                "2001å€‰åº«æ¬ å“æ—¥æ•°": vals[2],
                "ä¸‰å€‰åº«æ¬ å“æ—¥æ•°åˆè¨ˆ": total
            })
    df_ketsu = pd.DataFrame(ketsu_records)

    df_ship = df_ship_raw.copy()
    st.sidebar.title("å‡ºè·ãƒ‡ãƒ¼ã‚¿åˆ—ãƒãƒƒãƒ”ãƒ³ã‚°")
    date_col = st.sidebar.selectbox("æ—¥ä»˜åˆ—ï¼ˆå¹´æœˆç”¨ï¼‰", df_ship.columns)
    code_col = st.sidebar.selectbox("å•†å“ã‚³ãƒ¼ãƒ‰åˆ—", df_ship.columns)
    trade_col = st.sidebar.selectbox("è²¿æ˜“ä¼šç¤¾åˆ—", df_ship.columns)

    # å•†å“ååˆ—ã®è‡ªå‹•æ¤œå‡ºã¨æ¨™æº–åŒ–ï¼ˆä¿®å¤é€»è¾‘ï¼Œç¡®ä¿åç»­èƒ½ç”¨ï¼‰
    possible_name_cols = ['å•†å“å', 'å“å', 'å•†å“åç§°']
    for name_col in possible_name_cols:
        if name_col in df_ship.columns:
            df_ship.rename(columns={name_col: 'å•†å“å'}, inplace=True)
            break
    if 'å•†å“å' not in df_ship.columns:
        df_ship['å•†å“å'] = None  # å¦‚æœæ²¡æœ‰å•†å“ååˆ—ï¼Œä¹Ÿè¦å ä½ï¼Œé¿å…åç»­mergeå‡ºé”™

    df_ship[date_col] = pd.to_datetime(df_ship[date_col], errors='coerce')
    df_ship = df_ship.dropna(subset=[date_col])
    df_ship['å¹´æœˆ'] = df_ship[date_col].dt.month.astype(str) + 'æœˆ'

    df_ship[code_col] = df_ship[code_col].astype(str).str.strip()
    df_ketsu["å•†å“ã‚³ãƒ¼ãƒ‰"] = df_ketsu["å•†å“ã‚³ãƒ¼ãƒ‰"].astype(str).str.strip()

    dummy_df = df_ship[[trade_col, code_col, 'å¹´æœˆ', 'æ¬ å“ç†ç”±']].dropna()
    dummy_df['æ¬ å“ç†ç”±'] = dummy_df['æ¬ å“ç†ç”±'].astype(str).str.split(',')
    dummy_df = dummy_df.explode('æ¬ å“ç†ç”±')
    dummy_df['æ¬ å“ç†ç”±'] = dummy_df['æ¬ å“ç†ç”±'].str.strip()
    dummies = pd.get_dummies(dummy_df['æ¬ å“ç†ç”±'], prefix='æ¬ å“ç†ç”±', dtype=int)
    dummy_df = pd.concat([dummy_df[[trade_col, code_col, 'å¹´æœˆ']], dummies], axis=1)
    dummy_grouped = dummy_df.groupby([trade_col, code_col, 'å¹´æœˆ'], as_index=False).sum()
    dummy_grouped['æ¬ å“ç†ç”±_åˆè¨ˆ'] = dummy_grouped.drop(columns=[trade_col, code_col, 'å¹´æœˆ']).sum(axis=1)
    dummy_cols = [col for col in dummy_grouped.columns if col.startswith('æ¬ å“ç†ç”±_') and col != 'æ¬ å“ç†ç”±_åˆè¨ˆ']

    df_ship['å‡ºè²¨å›æ•°'] = 1
    ship_count_df = df_ship.groupby([code_col, 'å¹´æœˆ'], as_index=False)['å‡ºè²¨å›æ•°'].count()

    drop_cols = ['å·¥å ´æŒ‡ç¤ºæ—¥', 'ç¢ºå®šæ—¥', 'Order No', 'ç®¡ç†ç•ªå·']
    df_ship = df_ship.drop(columns=[col for col in drop_cols if col in df_ship.columns])
    group_cols = [trade_col, code_col, 'å¹´æœˆ']
    numeric_cols = df_ship.select_dtypes(include=['number']).columns.tolist()
    non_numeric_cols = [col for col in df_ship.columns if col not in numeric_cols and col not in group_cols and col != date_col]
    agg_dict = {col: 'sum' for col in numeric_cols}
    for col in non_numeric_cols:
        agg_dict[col] = 'first'
    if 'å•†å“å' in df_ship.columns:
        agg_dict['å•†å“å'] = 'first'

    df_ship_grouped = df_ship.groupby(group_cols, as_index=False).agg(agg_dict)

    df_merged = pd.merge(df_ship_grouped, df_ketsu, left_on=[code_col, 'å¹´æœˆ'], right_on=["å•†å“ã‚³ãƒ¼ãƒ‰", "å¹´æœˆ"], how="left")
    
    # merge åä¿®æ­£å•†å“åå­—æ®µï¼ˆå¦‚æœäº§ç”Ÿäº† _x/_yï¼‰
    if 'å•†å“å_x' in df_merged.columns and 'å•†å“å_y' in df_merged.columns:
        df_merged['å•†å“å'] = df_merged['å•†å“å_x']
        df_merged.drop(columns=['å•†å“å_x', 'å•†å“å_y'], inplace=True)
    elif 'å•†å“å_x' in df_merged.columns:
        df_merged.rename(columns={'å•†å“å_x': 'å•†å“å'}, inplace=True)
    elif 'å•†å“å' not in df_merged.columns and 'å•†å“å_y' in df_merged.columns:
        df_merged.rename(columns={'å•†å“å_y': 'å•†å“å'}, inplace=True)
    
    df_merged = pd.merge(df_merged, dummy_grouped, on=[trade_col, code_col, 'å¹´æœˆ'], how="left")
    df_merged = pd.merge(df_merged, ship_count_df, on=[code_col, 'å¹´æœˆ'], how="left")
    if not df_status.empty:
        df_status['å•†å“ã‚³ãƒ¼ãƒ‰'] = df_status['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str).str.strip()
        df_merged = pd.merge(df_merged, df_status[['å•†å“ã‚³ãƒ¼ãƒ‰', 'å•†å“çŠ¶æ…‹']], on='å•†å“ã‚³ãƒ¼ãƒ‰', how='left')

    df_merged.fillna(0, inplace=True)
    df_merged['ä¸‰å€‰åº«æ¬ å“æ—¥æ•°åˆè¨ˆ'] = (
        df_merged.get('0001å€‰åº«æ¬ å“æ—¥æ•°', 0) +
        df_merged.get('1001å€‰åº«æ¬ å“æ—¥æ•°', 0) +
        df_merged.get('2001å€‰åº«æ¬ å“æ—¥æ•°', 0)
    )

    # å‡ºè²¨å›æ•°å»é‡å¤„ç†ï¼ˆä¿ç•™ _x ç‰ˆæœ¬ï¼‰
    if 'å‡ºè²¨å›æ•°_x' in df_merged.columns and 'å‡ºè²¨å›æ•°_y' in df_merged.columns:
        df_merged['å‡ºè²¨å›æ•°'] = df_merged['å‡ºè²¨å›æ•°_x']
        df_merged.drop(columns=['å‡ºè²¨å›æ•°_x', 'å‡ºè²¨å›æ•°_y'], inplace=True)

    # âœ… æŒ‡å®šæœ€ç»ˆè¾“å‡ºåˆ—é¡ºåºï¼ˆç»Ÿä¸€æ ¼å¼ï¼‰
    dummy_cols = [col for col in df_merged.columns if col.startswith('æ¬ å“ç†ç”±_') and col != 'æ¬ å“ç†ç”±_åˆè¨ˆ']

    ordered_cols = ['å•†å“çŠ¶æ…‹', 'å¹´æœˆ', 'å•†å“ã‚³ãƒ¼ãƒ‰']
    for col in ['å•†å“å', trade_col, 'å·¥å ´å']:
        if col in df_merged.columns:
            ordered_cols.append(col)


    # å‡ºè·ç±»æ•°å€¼åˆ—ï¼ˆéæ§åˆ¶åˆ—ï¼‰
    skip_cols = set(ordered_cols + dummy_cols + [
    '0001å€‰åº«æ¬ å“æ—¥æ•°', '1001å€‰åº«æ¬ å“æ—¥æ•°', '2001å€‰åº«æ¬ å“æ—¥æ•°',
    'ä¸‰å€‰åº«æ¬ å“æ—¥æ•°åˆè¨ˆ', 'å‡ºè²¨å›æ•°', 'æ¬ å“ç†ç”±_åˆè¨ˆ'])
    ship_numeric = [col for col in df_merged.columns if col not in skip_cols and df_merged[col].dtype != 'O']


    # æ‹¼æ¥æœ€ç»ˆé¡ºåº
    final_cols = (
    ordered_cols +
    ship_numeric +
    ['å‡ºè²¨å›æ•°', 'æ¬ å“ç†ç”±_åˆè¨ˆ', '0001å€‰åº«æ¬ å“æ—¥æ•°', '1001å€‰åº«æ¬ å“æ—¥æ•°', '2001å€‰åº«æ¬ å“æ—¥æ•°', 'ä¸‰å€‰åº«æ¬ å“æ—¥æ•°åˆè¨ˆ'] +
    dummy_cols)
    final_cols = [col for col in final_cols if col in df_merged.columns]
    df_final = df_merged[final_cols].drop_duplicates()

    st.subheader("çµ±åˆçµæœãƒ‡ãƒ¼ã‚¿")
    st.dataframe(df_final)

    df_sales_long = pd.DataFrame()
    if isinstance(df_sales_raw, pd.DataFrame) and not df_sales_raw.empty:
        try:
            id_vars = ['å•†å“ã‚³ãƒ¼ãƒ‰']
            value_vars = [col for col in df_sales_raw.columns if re.search(r'20\d{2}[/å¹´\-]\d{1,2}', str(col))]
            df_sales_long = df_sales_raw.melt(id_vars=id_vars, value_vars=value_vars, var_name='å¹´æœˆ', value_name='è²©å£²é‡')
            df_sales_long['å•†å“ã‚³ãƒ¼ãƒ‰'] = df_sales_long['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str).str.strip()
            df_sales_long['å¹´æœˆ'] = df_sales_long['å¹´æœˆ'].astype(str)
            df_sales_long['å¹´æœˆ'] = pd.to_datetime(df_sales_long['å¹´æœˆ'], errors='coerce')
            df_sales_long = df_sales_long.dropna(subset=['å¹´æœˆ'])
            df_sales_long['å¹´æœˆ'] = df_sales_long['å¹´æœˆ'].dt.strftime('%Y/%m')

            è£œå®Œåˆ— = ['å•†å“ã‚³ãƒ¼ãƒ‰', 'å•†å“å', 'è²¿æ˜“ä¼šç¤¾å', 'å·¥å ´å', 'å•†å“çŠ¶æ…‹']
            df_sales_info = df_sales_raw[è£œå®Œåˆ—].drop_duplicates(subset=['å•†å“ã‚³ãƒ¼ãƒ‰'], keep='first')
            df_sales_long = pd.merge(df_sales_long, df_sales_info, on='å•†å“ã‚³ãƒ¼ãƒ‰', how='left')

            desired_cols = ['å•†å“çŠ¶æ…‹', 'å¹´æœˆ', 'å•†å“ã‚³ãƒ¼ãƒ‰', 'å•†å“å', 'è²¿æ˜“ä¼šç¤¾å', 'å·¥å ´å', 'è²©å£²é‡']
            df_sales_long = df_sales_long[[col for col in desired_cols if col in df_sales_long.columns]]

            st.subheader("ğŸ“Š è²©å£²é‡ãƒ‡ãƒ¼ã‚¿ï¼ˆæ•´å½¢å¾Œï¼‰")
            st.dataframe(df_sales_long)

        except Exception as e:
            st.warning(f"è²©å£²é‡ãƒ‡ãƒ¼ã‚¿ã®æ•´å½¢æ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine='openpyxl') as writer:
        df_final.to_excel(writer, index=False, sheet_name="çµ±åˆçµæœ")
        if not df_sales_long.empty:
            df_sales_long.to_excel(writer, index=False, sheet_name="è²©å£²é‡ãƒ‡ãƒ¼ã‚¿")
    buf.seek(0)

    st.download_button(
        "Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆçµ±åˆçµæœï¼‹è²©å£²é‡ï¼‰",
        data=buf,
        file_name="çµ±åˆçµæœ_çŠ¶æ…‹ä»˜ã_è²©å£²é‡ä»˜ã.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
    
    st.session_state.cleaned_df = df_final  # âœ… ä¼ ç»™åˆ†æé¡µçš„æ•°æ®ï¼ˆæ•´åˆç»“æœï¼‰
